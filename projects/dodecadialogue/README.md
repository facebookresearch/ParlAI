## The Dialogue Dodecathlon

### _Open-Domain Knowledge and Image Grounded Conversational Agents_

Kurt Shuster, Da Ju, Stephen Roller, Emily Dinan, Y-Lan Boureau, Jason Weston

## Abstract

We introduce  dodecaDialogue:  a set of 12 tasks which measure if a conversational agent can communicate
engagingly with personality and empathy, ask questions, answer questions by utilizing knowledge resources,
discuss topics and situations, and perceive and converse about images. By multi-tasking on such a broad
large-scale set of data we hope to both move towards and measure progress in producing a single unified agent
that can perceive, reason and converse with humans in an open-domain setting. We show that such multi-tasking
improves over a BERT pre-trained baseline, largely due to multi-tasking with very large dialogue datasets in
a similar domain, and that the multi-tasking in general provides gains to both text and image-based tasks using
several metrics in both the fine-tune and task transfer settings. We obtain state-of-the-art results on many
of the tasks, providing a strong baseline for this challenge.

## Paper

[Link](https://drive.google.com/open?id=1WFf5hqMdjJ9MaCU76lCUwNm5G6wWiX6y)

## dodecaDialogue Subtasks

<p align="center"><img width="85%" src="Tasks.png" /></p>

## Baseline Results

<p align="center"><img width="85%" src="Baseline.png" /></p>

## Baseline Compared to Existing Approaches

<p align="center"><img width="85%" src="Comparison.png" /></p>

## Model Examples

<p align="center"><img width="85%" src="wizard.png" /></p>

<p align="center"><img width="85%" src="image_chat.png" /></p>
