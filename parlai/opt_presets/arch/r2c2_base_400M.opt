{
  "activation": "gelu",
  "attention_dropout": 0.1,
  "delimiter": "\n",
  "dict_tokenizer": "gpt2",
  "dropout": 0.1,
  "embedding_size": 1024,
  "embeddings_scale": true,
  "ffn_size": 4096,
  "force_fp16_tokens": true,
  "history_add_global_end_token": null,
  "init_model": "zoo:seeker/r2c2_base_400M/model",
  "label_truncate": 1024,
  "learn_positional_embeddings": true,
  "model": "bart",
  "n_decoder_layers": 12,
  "n_encoder_layers": 12,
  "n_heads": 16,
  "n_layers": 12,
  "n_positions": 1024,
  "n_segments": 0,
  "output_scaling": 1,
  "rank_candidates": false,
  "relu_dropout": 0,
  "share_word_embeddings": true,
  "split_lines": true,
  "text_truncate": 1024,
  "truncate": 1024,
  "variant": "prelayernorm"
}