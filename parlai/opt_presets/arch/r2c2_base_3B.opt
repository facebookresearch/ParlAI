{
  "activation": "gelu",
  "delimiter": "\n",
  "dict_tokenizer": "gpt2",
  "embedding_size": 2048,
  "embeddings_scale": true,
  "ffn_size": 8192,
  "force_fp16_tokens": true,
  "history_add_global_end_token": "end",
  "init_model": "zoo:seeker/r2c2_base_3B/model",
  "label_truncate": 1024,
  "learn_positional_embeddings": true,
  "model": "bart",
  "n_decoder_layers": 22,
  "n_encoder_layers": 22,
  "n_heads": 32,
  "n_layers": 22,
  "n_positions": 1024,
  "n_segments": 0,
  "output_scaling": 1,
  "share_word_embeddings": true,
  "split_lines": true,
  "text_truncate": 1024,
  "truncate": 1024,
  "variant": "prelayernorm"
}