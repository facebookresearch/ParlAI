version: 2.1

# -------------------------------------------------------------------------------------
# environments where we run our jobs
# -------------------------------------------------------------------------------------
executors:
  standard_cpu38:
    docker:
      - image: circleci/python:3.8.0-buster-node
    environment:
      PYTHONUNBUFFERED: 1
    resource_class: xlarge

  standard_cpu37:
    docker:
      - image: circleci/python:3.7.5-buster-node
    environment:
      PYTHONUNBUFFERED: 1
    resource_class: xlarge

  small_cpu37:
    docker:
      - image: circleci/python:3.7.5-buster-node
    environment:
      PYTHONUNBUFFERED: 1
    resource_class: medium

  standard_cpu36:
    docker:
      - image: circleci/python:3.6.9-buster-node
    environment:
      PYTHONUNBUFFERED: 1
    resource_class: xlarge

  osx_cpu37:
    macos:
      # https://circleci.com/docs/2.0/testing-ios/
      xcode: "11.3.1"
    environment:
      PYTHON: 3.7.1
      PYTHONUNBUFFERED: 1
      HOMEBREW_NO_AUTO_UPDATE: 1

  gpu:
    environment:
      CUDA_VERSION: "10.2"
      PYTHONUNBUFFERED: 1
    machine:
      image: ubuntu-1604:201903-01
    resource_class: gpu.medium # tesla m60

# -------------------------------------------------------------------------------------
# reusable commands
# -------------------------------------------------------------------------------------
commands:
  fixgit:
    # circleci sets master to the tip of the branch, which isn't super useful for us.
    # better if master looks like it would on our local machines
    description: Fixes git
    steps:
      - run:
          name: Fixes git
          command: |
            ( [[ "$CIRCLE_BRANCH" != "master" ]] && git branch -f master origin/master ) || true

  setup:
    description: Sets up the virtual environment
    steps:
      - run:
          name: Sets up the virtual environment
          command: |
            mkdir -p ~/venv
            virtualenv --python=python3 ~/venv
            echo ". ~/venv/bin/activate" >> $BASH_ENV
            . ~/venv/bin/activate
            python --version

  codecov:
    description: Coverage report
    steps:
      - run:
          name: Coverage report
          command: |
            python -m codecov --flags $CIRCLE_JOB
            mkdir -p ~/ParlAI/data

  installdeps:
    description: Install basic dependencies
    steps:
      - run:
          name: Installs basic dependencies
          command: |
            python -m pip install --progress-bar off --upgrade pip setuptools
            python -m pip install --progress-bar off coverage
            python -m pip install --progress-bar off codecov
            mkdir -p ~/ParlAI/test-results
            pip install -v -r requirements.txt
            python setup.py develop
            python -c "import nltk; nltk.download('punkt')"

  installtorchgpu16:
    description: Install torch GPU and dependencies
    steps:
      - run:
          name: Install torch GPU and dependencies
          command: |
            python -m pip install --progress-bar off torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html
            python -m pip install --progress-bar off 'torchtext==0.7.0'
            python -m pip install --progress-bar off pytorch-pretrained-bert
            python -m pip install --progress-bar off transformers
            python -m pip install --progress-bar off 'fairseq==0.10.0'
            python -c 'import torch; print("Torch version:", torch.__version__)'
            python -m torch.utils.collect_env

  installtorchgpu15:
    description: Install torch GPU and dependencies
    steps:
      - run:
          name: Install torch GPU and dependencies
          command: |
            python -m pip install --progress-bar off 'torch==1.5.1'
            python -c 'import torch; print("Torch version:", torch.__version__)'
            python -m torch.utils.collect_env

  installtorchgpu14:
    description: Install torch GPU and dependencies
    steps:
      - run:
          name: Install torch GPU and dependencies
          command: |
            python -m pip install --progress-bar off 'numpy'
            python -m pip install --progress-bar off 'torch==1.4.0'
            python -c 'import torch; print("Torch version:", torch.__version__)'
            python -m torch.utils.collect_env

  installtorchcpuosx:
    description: Install torch CPU and dependencies
    steps:
      - run:
          name: Install torch CPU and dependencies
          command: |
            python -m pip install --progress-bar off torch==1.6.0
            python -c 'import torch; print("Torch version:", torch.__version__)'
            python -m torch.utils.collect_env

  installtorchcpu:
    description: Install torch CPU and dependencies
    steps:
      - run:
          name: Install torch CPU and dependencies
          command: |
            python -m pip install --progress-bar off torch==1.6.0+cpu torchtext==0.7.0 torchvision==0.7.0+cpu -f https://download.pytorch.org/whl/torch_stable.html
            python -c 'import torch; print("Torch version:", torch.__version__)'
            python -m torch.utils.collect_env

  installdetectrondeps:
    description: Install opencv, vqa-maskrcnn-benchmark
    steps:
      - run:
          name: Install opencv, vqa-maskrcnn-benchmark
          command: |
            python -m pip install opencv-python==4.2.0.34
            git clone https://gitlab.com/vedanuj/vqa-maskrcnn-benchmark.git maskbench
            cd maskbench; git checkout 4c168a637f45dc69efed384c00a7f916f57b25b8 -b stable
            python setup.py develop; cd -

  installcrowdsourcingdeps:
    description: Install Mephisto
    steps:
      - run:
            name: Install Mephisto
            command: |
              cd ..
              git clone git@github.com:facebookresearch/Mephisto.git Mephisto
              cd Mephisto; git checkout 8f315bfe42ba9643164d3d3d61d7d22609b3ab10 -b stable
              pip install -r requirements.txt
              python setup.py develop
              # `echo` so that ENTER will be pressed at the prompt
              echo | mephisto check

  setupcuda:
    description: Setup CUDA
    steps:
      - run:
          name: Setup CUDA
          working_directory: ~/
          command: |
            # download and install nvidia drivers, cuda, etc
            wget --quiet --no-clobber -P ~/nvidia-downloads 'https://s3.amazonaws.com/ossci-linux/nvidia_driver/NVIDIA-Linux-x86_64-430.40.run'
            time sudo /bin/bash ~/nvidia-downloads/NVIDIA-Linux-x86_64-430.40.run --no-drm -q --ui=none
            echo "Done installing NVIDIA drivers."
            pyenv versions
            nvidia-smi
            pyenv global 3.7.0

  findtests:
    description: Find tests to run
    parameters:
      marker:
        type: string
    steps:
      - run:
          working_directory: ~/ParlAI
          name: Find tests to run
          command: |
            mkdir -p ~/ParlAI/data/models
            python -m pytest -m << parameters.marker >> --collect-only | grep '<'  | sed "s/^ *//" > teststorun.txt
            cat teststorun.txt

  runtests:
    description: Run a full suite of unit tests
    parameters:
      cachename:
        description: the key for our caches. date and checksum will be added
        type: string
      marker:
        description: the pytest marker to filter on
        type: string
      more_installs:
        description: Any extra installation commands to run
        type: steps
        default: []
      install_cuda:
        description: Should we install cuda?
        type: boolean
        default: false
      pytest_flags:
        description: extra flags to pass to pytest
        type: string
        default: "-v"
    steps:
      - checkout
      - when:
          condition: << parameters.install_cuda >>
          steps:
            - setupcuda
      - fixgit
      - restore_cache:
          key: deps-20201110-<< parameters.cachename >>-{{ checksum "requirements.txt" }}
      - setup
      - installdeps
      - << parameters.more_installs >>
      - save_cache:
          key: deps-20201110-<< parameters.cachename >>-{{ checksum "requirements.txt" }}
          paths:
            - "~/venv/bin"
            - "~/venv/lib"
      - findtests:
          marker: << parameters.marker >>
      - restore_cache:
          key: data-20201110-<< parameters.cachename >>-{{ checksum "teststorun.txt" }}
      - run:
          name: Run tests
          no_output_timeout: 60m
          command: |
            coverage run -m pytest -m << parameters.marker >> << parameters.pytest_flags >> --junitxml=test-results/junit.xml
      - save_cache:
          key: data-20200904-<< parameters.cachename >>-{{ checksum "teststorun.txt" }}
          paths:
            - "~/ParlAI/data"
      - codecov
      - store_test_results:
          path: test-results

  website:
    description: Build (and possibly deploy) the website
    parameters:
      deploy:
        type: boolean
        default: false
    steps:
      - checkout
      - fixgit
      - restore_cache:
          key: deps-20200921-bw-{{ checksum "requirements.txt" }}
      - setup
      - installdeps
      - installtorchgpu16
      - save_cache:
          key: deps-20200921-bw-{{ checksum "requirements.txt" }}
          paths:
            - "~/venv/bin"
            - "~/venv/lib"
      - run:
          working_directory: ~/ParlAI/website
          name: build the website
          command: make
      - run:
          name: zip up the website
          working_directory: ~/ParlAI/website/build/
          command: |
            zip -r ~/ParlAI/website.zip *
      - store_artifacts:
          path: website.zip
      - run:
          name: check for bad links
          working_directory: ~/ParlAI/
          command: |
            sudo apt-get install linkchecker
            python -m http.server --directory website/build >/dev/null &
            linkchecker http://localhost:8000/
            kill %1
      - when:
         condition: << parameters.deploy >>
         steps:
         - run:
             working_directory: ~/ParlAI/
             name: Upload the website
             command: |
               pip install s3cmd
               s3cmd --access_key="${S3_ACCESS_KEY}" --secret_key="${S3_SECRET_KEY}" sync -f --delete-removed website/build/ "s3://parl.ai/"
               s3cmd --access_key="${S3_ACCESS_KEY}" --secret_key="${S3_SECRET_KEY}" setacl --acl-public --recursive "s3://parl.ai/"
               s3cmd --access_key="${S3_ACCESS_KEY}" --secret_key="${S3_SECRET_KEY}" modify --add-header="Content-type:text/css" 's3://parl.ai/static/css/*' 's3://parl.ai/docs/_static/*.css' 's3://parl.ai/docs/_static/css/*.css'


# -------------------------------------------------------------------------------------
# Actual jobs
# -------------------------------------------------------------------------------------
jobs:
  cleaninstall_36:
    executor: standard_cpu36
    working_directory: ~/ParlAI
    parallelism: 1
    steps:
      - checkout
      - fixgit
      - setup
      - run:
          name: Test installation instructions
          no_output_timeout: 60m
          command: |
            python -m pip install --progress-bar off --upgrade pip setuptools
            python setup.py develop
            parlai display_data -t integration_tests

  unittests_osx:
    executor: osx_cpu37
    working_directory: ~/ParlAI
    parallelism: 2
    steps:
      - runtests:
          cachename: osx
          marker: unit

  unittests_36:
    executor: standard_cpu36
    working_directory: ~/ParlAI
    parallelism: 8
    steps:
      - runtests:
          more_installs:
            - installtorchcpu
          cachename: ut36
          marker: unit

  unittests_37:
    executor: standard_cpu38
    working_directory: ~/ParlAI
    parallelism: 2
    steps:
      - runtests:
          more_installs:
            - installtorchcpu
          cachename: ut37
          marker: unit

  unittests_38:
    executor: standard_cpu38
    working_directory: ~/ParlAI
    parallelism: 2
    steps:
      - runtests:
          more_installs:
            - installtorchcpu
          cachename: ut38
          marker: unit

  unittests_gpu14:
    executor: gpu
    working_directory: ~/ParlAI
    parallelism: 2
    steps:
      - runtests:
          more_installs:
            - installtorchgpu14
          install_cuda: true
          cachename: gpu14
          marker: unit

  unittests_gpu15:
    executor: gpu
    working_directory: ~/ParlAI
    parallelism: 2
    steps:
      - runtests:
          more_installs:
            - installtorchgpu15
          install_cuda: true
          cachename: gpu15
          marker: unit

  unittests_gpu16:
    executor: gpu
    working_directory: ~/ParlAI
    parallelism: 8
    steps:
      - runtests:
          more_installs:
            - installtorchgpu16
            - installdetectrondeps
          install_cuda: true
          cachename: gpu16
          marker: unit

  long_gpu_tests:
    executor: gpu
    working_directory: ~/ParlAI
    parallelism: 8
    steps:
      - runtests:
          more_installs:
            - installtorchgpu16
            - installdetectrondeps
          install_cuda: true
          cachename: nightly
          marker: nightly_gpu
          pytest_flags: -v -s

  crowdsourcing_tests:
    executor: small_cpu37
    working_directory: ~/ParlAI
    parallelism: 1
    steps:
      - runtests:
          cachename: crowdsourcing
          marker: crowdsourcing
          more_installs:
            - installcrowdsourcingdeps

  teacher_tests:
    executor: standard_cpu37
    working_directory: ~/ParlAI
    parallelism: 8
    steps:
      - runtests:
          cachename: teacher
          marker: teacher

  mturk_tests:
    executor: small_cpu37
    working_directory: ~/ParlAI
    parallelism: 1
    steps:
      - runtests:
          cachename: mturk
          marker: mturk

  build_website:
    executor: small_cpu37
    working_directory: ~/ParlAI
    parallelism: 1
    steps:
      - website:
          deploy: false

  deploy_website:
    executor: small_cpu37
    working_directory: ~/ParlAI
    steps:
      - website:
          deploy: true

  test_website:
    executor: small_cpu37
    working_directory: ~/ParlAI
    steps:
      - run:
          name: Test the website
          command: |
            echo 'Testing root page:'
            curl -f -i 'https://parl.ai/'
            echo
            echo 'Testing root css:'
            curl -f -i 'https://parl.ai/static/css/parlai.css'
            echo
            echo 'Testing docs page'
            curl -f -i 'https://parl.ai/docs/'
            echo
            echo 'Testing docs css'
            curl -f -i 'https://parl.ai/docs/_static/css/parlai_theme.css'


workflows:
  version: 2
  commit:
    jobs:
      - cleaninstall_36
      - unittests_gpu16
      - unittests_gpu15:
          requires:
            - unittests_37
            - unittests_gpu16
      - unittests_gpu14:
          requires:
            - unittests_37
            - unittests_gpu16
      - unittests_38:
          requires:
            - unittests_37
            - unittests_gpu16
      - unittests_37
      - unittests_36:
          requires:
            - unittests_37
            - unittests_gpu16
      - mturk_tests
      - unittests_osx:
          requires:
            - unittests_gpu16
            - unittests_37
      - long_gpu_tests:
          requires:
            - unittests_gpu16
            - unittests_37
      - crowdsourcing_tests:
          requires:
            - unittests_gpu16
            - unittests_37
      - teacher_tests:
          requires:
            - unittests_gpu16
            - unittests_37
      - build_website:
          filters:
            branches:
              ignore: master
      - deploy_website:
          filters:
            branches:
              only: master
      - test_website:
          requires:
            - deploy_website
