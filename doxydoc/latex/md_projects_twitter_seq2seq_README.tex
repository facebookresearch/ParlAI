Running any of the following scripts will automatically download the pretrained model.

The expected perplexities are 61.\+28 on the validation set and 63.\+06 on the test set.

Run the {\ttfamily eval\+\_\+f1.\+py} script to evaluate the f1 score of the pretrained model on the twitter dev set. (Run {\ttfamily python eval\+\_\+f1.\+py -\/dt test} to run on the test set.)

The {\ttfamily eval\+\_\+ppl.\+py} to run a standardized perplexity evaluation, which asks for one token at a time from the model.

Run the {\ttfamily interactive.\+py} script to talk to the pretrained model directly.

\subsection*{Train your own}

Run {\ttfamily python train.\+py} to train your own using the same hyperparameters as the pretrained model.

You can override any of these from the command line, e.\+g. {\ttfamily python train.\+py -\/bs 16 -\/lr 0.\+0001 -\/opt adam}.

\subsection*{Sweep results}

In case you\textquotesingle{}re interested, the results of an example sweep over parameters is contained in {\ttfamily sweep\+\_\+ppl.\+csv}.

The first column in that file contains the best validation perplexity for that run, and the remaining columns contain a hyperparameter value.

Note that this is the perplexity found by taking the exponent of the cross entropy loss--this is less precise than the ppl calculated with the {\ttfamily eval\+\_\+ppl.\+py} script here (though they are correlated). 