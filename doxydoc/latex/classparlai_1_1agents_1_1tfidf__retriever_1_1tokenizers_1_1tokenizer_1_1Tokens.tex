\hypertarget{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens}{}\section{parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens Class Reference}
\label{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens}\index{parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens@{parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens}}


Inheritance diagram for parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=231pt]{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens__inherit__graph}
\end{center}
\end{figure}


Collaboration diagram for parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=231pt]{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens__coll__graph}
\end{center}
\end{figure}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
def \hyperlink{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_a302d05e18dc97ba20cdfb879f3442b88}{\+\_\+\+\_\+init\+\_\+\+\_\+} (self, \hyperlink{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_ad5068b92d72245d43fd75dbb4c070a27}{data}, \hyperlink{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_a394834203475385444a933440dcdd026}{annotators}, \hyperlink{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_ada7339fd7da0200a4260970771f9bfe9}{opts}=None)
\item 
def \hyperlink{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_aa4d7fdac5660d51ef4b59712142c5ef4}{\+\_\+\+\_\+len\+\_\+\+\_\+} (self)
\item 
def \hyperlink{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_a8e68a443796116164126c7216f5963d3}{slice} (self, i=None, j=None)
\item 
def \hyperlink{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_a1bea40b1ea8e1772fb8ae6c2157ee819}{untokenize} (self)
\item 
def \hyperlink{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_a81b6d47a051c87c7f885a6f7db5ac891}{words} (self, uncased=False)
\item 
def \hyperlink{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_ad64d5292cef77a2a02193ba836875ba7}{offsets} (self)
\item 
def \hyperlink{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_a5aa226b8190b5e72dbe0515caf0a21d6}{pos} (self)
\item 
def \hyperlink{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_acc0353a15e5585dae3bd08943b9abe0c}{lemmas} (self)
\item 
def \hyperlink{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_ab5d74ebfda5597b48f1ddc5f607292de}{entities} (self)
\item 
def \hyperlink{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_ae66797d00194acc3c67b42c7cf17dabf}{ngrams} (self, n=1, uncased=False, filter\+\_\+fn=None, as\+\_\+strings=True)
\item 
def \hyperlink{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_af76da989bcd6090398f0e63b8c30de22}{entity\+\_\+groups} (self)
\end{DoxyCompactItemize}
\subsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
\hyperlink{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_ad5068b92d72245d43fd75dbb4c070a27}{data}
\item 
\hyperlink{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_a394834203475385444a933440dcdd026}{annotators}
\item 
\hyperlink{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_ada7339fd7da0200a4260970771f9bfe9}{opts}
\end{DoxyCompactItemize}
\subsection*{Static Public Attributes}
\begin{DoxyCompactItemize}
\item 
int \hyperlink{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_a9aa424cb61b8e4fa45019647aa3a469f}{T\+E\+XT} = 0
\item 
int \hyperlink{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_ac1965a5c7e633c9824f5de66b5211325}{T\+E\+X\+T\+\_\+\+WS} = 1
\item 
int \hyperlink{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_a854cddac2a5c84a5d770aa938f304f09}{S\+P\+AN} = 2
\item 
int \hyperlink{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_ac86fd8e346abb9582109d8e11e5f9b48}{P\+OS} = 3
\item 
int \hyperlink{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_a0edd5b712de93117c645a869bda3206a}{L\+E\+M\+MA} = 4
\item 
int \hyperlink{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_a23de330eaa8a95b1eec932b960384516}{N\+ER} = 5
\end{DoxyCompactItemize}


\subsection{Detailed Description}
\begin{DoxyVerb}A class to represent a list of tokenized text.\end{DoxyVerb}
 

Definition at line 12 of file tokenizer.\+py.



\subsection{Constructor \& Destructor Documentation}
\mbox{\Hypertarget{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_a302d05e18dc97ba20cdfb879f3442b88}\label{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_a302d05e18dc97ba20cdfb879f3442b88}} 
\index{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}!\+\_\+\+\_\+init\+\_\+\+\_\+@{\+\_\+\+\_\+init\+\_\+\+\_\+}}
\index{\+\_\+\+\_\+init\+\_\+\+\_\+@{\+\_\+\+\_\+init\+\_\+\+\_\+}!parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}}
\subsubsection{\texorpdfstring{\+\_\+\+\_\+init\+\_\+\+\_\+()}{\_\_init\_\_()}}
{\footnotesize\ttfamily def parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+\_\+\+\_\+init\+\_\+\+\_\+ (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{data,  }\item[{}]{annotators,  }\item[{}]{opts = {\ttfamily None} }\end{DoxyParamCaption})}



Definition at line 22 of file tokenizer.\+py.



\subsection{Member Function Documentation}
\mbox{\Hypertarget{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_aa4d7fdac5660d51ef4b59712142c5ef4}\label{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_aa4d7fdac5660d51ef4b59712142c5ef4}} 
\index{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}!\+\_\+\+\_\+len\+\_\+\+\_\+@{\+\_\+\+\_\+len\+\_\+\+\_\+}}
\index{\+\_\+\+\_\+len\+\_\+\+\_\+@{\+\_\+\+\_\+len\+\_\+\+\_\+}!parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}}
\subsubsection{\texorpdfstring{\+\_\+\+\_\+len\+\_\+\+\_\+()}{\_\_len\_\_()}}
{\footnotesize\ttfamily def parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+\_\+\+\_\+len\+\_\+\+\_\+ (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}The number of tokens.\end{DoxyVerb}
 

Definition at line 27 of file tokenizer.\+py.



References parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+data.

\mbox{\Hypertarget{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_ab5d74ebfda5597b48f1ddc5f607292de}\label{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_ab5d74ebfda5597b48f1ddc5f607292de}} 
\index{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}!entities@{entities}}
\index{entities@{entities}!parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}}
\subsubsection{\texorpdfstring{entities()}{entities()}}
{\footnotesize\ttfamily def parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+entities (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Returns a list of named-entity-recognition tags of each token.
Returns None if this annotation was not included.
\end{DoxyVerb}
 

Definition at line 72 of file tokenizer.\+py.



References parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+annotators, parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+spacy\+\_\+tokenizer.\+Spacy\+Tokenizer.\+annotators, parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+corenlp\+\_\+tokenizer.\+Core\+N\+L\+P\+Tokenizer.\+annotators, parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+simple\+\_\+tokenizer.\+Simple\+Tokenizer.\+annotators, parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+regexp\+\_\+tokenizer.\+Regexp\+Tokenizer.\+annotators, parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+data, and parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+N\+ER.



Referenced by parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+entity\+\_\+groups().

Here is the caller graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_ab5d74ebfda5597b48f1ddc5f607292de_icgraph}
\end{center}
\end{figure}
\mbox{\Hypertarget{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_af76da989bcd6090398f0e63b8c30de22}\label{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_af76da989bcd6090398f0e63b8c30de22}} 
\index{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}!entity\+\_\+groups@{entity\+\_\+groups}}
\index{entity\+\_\+groups@{entity\+\_\+groups}!parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}}
\subsubsection{\texorpdfstring{entity\+\_\+groups()}{entity\_groups()}}
{\footnotesize\ttfamily def parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+entity\+\_\+groups (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Group consecutive entity tokens with the same NER tag.\end{DoxyVerb}
 

Definition at line 110 of file tokenizer.\+py.



References parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+entities(), parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+opts, parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+slice(), and parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+untokenize().

Here is the call graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_af76da989bcd6090398f0e63b8c30de22_cgraph}
\end{center}
\end{figure}
\mbox{\Hypertarget{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_acc0353a15e5585dae3bd08943b9abe0c}\label{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_acc0353a15e5585dae3bd08943b9abe0c}} 
\index{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}!lemmas@{lemmas}}
\index{lemmas@{lemmas}!parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}}
\subsubsection{\texorpdfstring{lemmas()}{lemmas()}}
{\footnotesize\ttfamily def parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+lemmas (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Returns a list of the lemmatized text of each token.
Returns None if this annotation was not included.
\end{DoxyVerb}
 

Definition at line 64 of file tokenizer.\+py.



References parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+annotators, parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+spacy\+\_\+tokenizer.\+Spacy\+Tokenizer.\+annotators, parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+corenlp\+\_\+tokenizer.\+Core\+N\+L\+P\+Tokenizer.\+annotators, parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+simple\+\_\+tokenizer.\+Simple\+Tokenizer.\+annotators, parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+regexp\+\_\+tokenizer.\+Regexp\+Tokenizer.\+annotators, parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+data, and parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+L\+E\+M\+MA.

\mbox{\Hypertarget{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_ae66797d00194acc3c67b42c7cf17dabf}\label{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_ae66797d00194acc3c67b42c7cf17dabf}} 
\index{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}!ngrams@{ngrams}}
\index{ngrams@{ngrams}!parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}}
\subsubsection{\texorpdfstring{ngrams()}{ngrams()}}
{\footnotesize\ttfamily def parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+ngrams (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{n = {\ttfamily 1},  }\item[{}]{uncased = {\ttfamily False},  }\item[{}]{filter\+\_\+fn = {\ttfamily None},  }\item[{}]{as\+\_\+strings = {\ttfamily True} }\end{DoxyParamCaption})}

\begin{DoxyVerb}Returns a list of all ngrams from length 1 to n.

Args:
    n: upper limit of ngram length
    uncased: lower cases text
    filter_fn: user function that takes in an ngram list and returns
      True or False to keep or not keep the ngram
    as_string: return the ngram as a string vs list
\end{DoxyVerb}
 

Definition at line 80 of file tokenizer.\+py.



References parlai.\+messenger.\+core.\+shared\+\_\+utils.\+format, parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+words(), parlai.\+tasks.\+integration\+\_\+tests.\+agents.\+Candidate\+Teacher.\+words, and parlai.\+tasks.\+integration\+\_\+tests.\+agents.\+Candidate\+Teacher\+Dataset.\+words.

Here is the call graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_ae66797d00194acc3c67b42c7cf17dabf_cgraph}
\end{center}
\end{figure}
\mbox{\Hypertarget{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_ad64d5292cef77a2a02193ba836875ba7}\label{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_ad64d5292cef77a2a02193ba836875ba7}} 
\index{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}!offsets@{offsets}}
\index{offsets@{offsets}!parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}}
\subsubsection{\texorpdfstring{offsets()}{offsets()}}
{\footnotesize\ttfamily def parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+offsets (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Returns a list of [start, end) character offsets of each token.\end{DoxyVerb}
 

Definition at line 52 of file tokenizer.\+py.



References parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+data, and parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+S\+P\+AN.

\mbox{\Hypertarget{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_a5aa226b8190b5e72dbe0515caf0a21d6}\label{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_a5aa226b8190b5e72dbe0515caf0a21d6}} 
\index{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}!pos@{pos}}
\index{pos@{pos}!parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}}
\subsubsection{\texorpdfstring{pos()}{pos()}}
{\footnotesize\ttfamily def parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+pos (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Returns a list of part-of-speech tags of each token.
Returns None if this annotation was not included.
\end{DoxyVerb}
 

Definition at line 56 of file tokenizer.\+py.



References parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+annotators, parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+spacy\+\_\+tokenizer.\+Spacy\+Tokenizer.\+annotators, parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+corenlp\+\_\+tokenizer.\+Core\+N\+L\+P\+Tokenizer.\+annotators, parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+simple\+\_\+tokenizer.\+Simple\+Tokenizer.\+annotators, parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+regexp\+\_\+tokenizer.\+Regexp\+Tokenizer.\+annotators, parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+data, and parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+P\+OS.

\mbox{\Hypertarget{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_a8e68a443796116164126c7216f5963d3}\label{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_a8e68a443796116164126c7216f5963d3}} 
\index{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}!slice@{slice}}
\index{slice@{slice}!parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}}
\subsubsection{\texorpdfstring{slice()}{slice()}}
{\footnotesize\ttfamily def parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+slice (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{i = {\ttfamily None},  }\item[{}]{j = {\ttfamily None} }\end{DoxyParamCaption})}

\begin{DoxyVerb}Return a view of the list of tokens from [i, j).\end{DoxyVerb}
 

Definition at line 31 of file tokenizer.\+py.



References parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+data.



Referenced by parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+entity\+\_\+groups().

Here is the caller graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_a8e68a443796116164126c7216f5963d3_icgraph}
\end{center}
\end{figure}
\mbox{\Hypertarget{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_a1bea40b1ea8e1772fb8ae6c2157ee819}\label{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_a1bea40b1ea8e1772fb8ae6c2157ee819}} 
\index{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}!untokenize@{untokenize}}
\index{untokenize@{untokenize}!parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}}
\subsubsection{\texorpdfstring{untokenize()}{untokenize()}}
{\footnotesize\ttfamily def parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+untokenize (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}

\begin{DoxyVerb}Returns the original text (with whitespace reinserted).\end{DoxyVerb}
 

Definition at line 37 of file tokenizer.\+py.



References parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+data, and parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+T\+E\+X\+T\+\_\+\+WS.



Referenced by parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+entity\+\_\+groups().

Here is the caller graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_a1bea40b1ea8e1772fb8ae6c2157ee819_icgraph}
\end{center}
\end{figure}
\mbox{\Hypertarget{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_a81b6d47a051c87c7f885a6f7db5ac891}\label{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_a81b6d47a051c87c7f885a6f7db5ac891}} 
\index{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}!words@{words}}
\index{words@{words}!parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}}
\subsubsection{\texorpdfstring{words()}{words()}}
{\footnotesize\ttfamily def parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+words (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{}]{uncased = {\ttfamily False} }\end{DoxyParamCaption})}

\begin{DoxyVerb}Returns a list of the text of each token

Args:
    uncased: lower cases text
\end{DoxyVerb}
 

Definition at line 41 of file tokenizer.\+py.



References parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+data, and parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+T\+E\+XT.



Referenced by parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+ngrams().

Here is the caller graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_a81b6d47a051c87c7f885a6f7db5ac891_icgraph}
\end{center}
\end{figure}


\subsection{Member Data Documentation}
\mbox{\Hypertarget{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_a394834203475385444a933440dcdd026}\label{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_a394834203475385444a933440dcdd026}} 
\index{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}!annotators@{annotators}}
\index{annotators@{annotators}!parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}}
\subsubsection{\texorpdfstring{annotators}{annotators}}
{\footnotesize\ttfamily parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+annotators}



Definition at line 24 of file tokenizer.\+py.



Referenced by parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+entities(), parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+lemmas(), and parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+pos().

\mbox{\Hypertarget{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_ad5068b92d72245d43fd75dbb4c070a27}\label{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_ad5068b92d72245d43fd75dbb4c070a27}} 
\index{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}!data@{data}}
\index{data@{data}!parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}}
\subsubsection{\texorpdfstring{data}{data}}
{\footnotesize\ttfamily parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+data}



Definition at line 23 of file tokenizer.\+py.



Referenced by parlai.\+tasks.\+flickr30k.\+agents.\+Flickr\+Dataset.\+\_\+\+\_\+getitem\+\_\+\+\_\+(), parlai.\+tasks.\+image\+\_\+chat.\+agents.\+Default\+Dataset.\+\_\+\+\_\+getitem\+\_\+\+\_\+(), parlai.\+tasks.\+personality\+\_\+captions.\+agents.\+Default\+Dataset.\+\_\+\+\_\+getitem\+\_\+\+\_\+(), parlai.\+tasks.\+integration\+\_\+tests.\+agents.\+Candidate\+Teacher\+Dataset.\+\_\+\+\_\+getitem\+\_\+\+\_\+(), parlai.\+core.\+pytorch\+\_\+data\+\_\+teacher.\+Parl\+A\+I\+Dataset.\+\_\+\+\_\+getitem\+\_\+\+\_\+(), stack\+\_\+rank\+\_\+evals.\+worlds.\+Example\+Generator.\+\_\+\+\_\+init\+\_\+\+\_\+(), parlai.\+tasks.\+integration\+\_\+tests.\+agents.\+Bad\+Example\+Teacher.\+\_\+\+\_\+init\+\_\+\+\_\+(), parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+\_\+\+\_\+len\+\_\+\+\_\+(), parlai.\+tasks.\+taskntalk.\+agents.\+Task\+N\+Talk\+Teacher.\+\_\+\+\_\+len\+\_\+\+\_\+(), parlai.\+tasks.\+taskntalk.\+agents.\+Task\+N\+Talk\+Teacher.\+act(), parlai.\+tasks.\+image\+\_\+chat.\+agents.\+Image\+Chat\+Teacher.\+add\+\_\+cmdline\+\_\+args(), parlai.\+tasks.\+personality\+\_\+captions.\+agents.\+Personality\+Captions\+Teacher.\+add\+\_\+cmdline\+\_\+args(), stack\+\_\+rank\+\_\+evals.\+worlds.\+Example\+Generator.\+add\+\_\+idx\+\_\+stack(), igc\+\_\+evals.\+worlds.\+I\+G\+C\+Example\+Generator.\+add\+\_\+idx\+\_\+stack(), image\+\_\+chat\+\_\+collection.\+worlds.\+Example\+Generator.\+add\+\_\+idx\+\_\+stack(), parlai.\+mturk.\+core.\+dev.\+socket\+\_\+manager.\+Packet.\+as\+\_\+dict(), parlai.\+mturk.\+core.\+legacy\+\_\+2018.\+socket\+\_\+manager.\+Packet.\+as\+\_\+dict(), parlai.\+mturk.\+core.\+socket\+\_\+manager.\+Packet.\+as\+\_\+dict(), parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+entities(), parlai.\+tasks.\+dailydialog.\+agents.\+Convai2\+Teacher.\+get(), parlai.\+tasks.\+dialogue\+\_\+nli.\+agents.\+Dialogue\+Nli\+Teacher.\+get(), parlai.\+tasks.\+talkthewalk.\+base.\+T\+T\+W\+Base.\+get(), parlai.\+tasks.\+dstc7.\+agents.\+D\+S\+T\+C7\+Teacher.\+get(), parlai.\+tasks.\+dialogue\+\_\+safety.\+base\+\_\+agent.\+\_\+\+Base\+Safety\+Teacher.\+get(), parlai.\+tasks.\+ubuntu.\+agents.\+Multiturn\+Teacher.\+get(), parlai.\+tasks.\+dailydialog.\+agents.\+No\+Start\+Teacher.\+get(), parlai.\+tasks.\+empathetic\+\_\+dialogues.\+agents.\+Empathetic\+Dialogue\+Teacher.\+get(), parlai.\+tasks.\+ccpe.\+agents.\+C\+C\+P\+E\+All\+Teacher.\+get(), parlai.\+tasks.\+dialogue\+\_\+safety.\+agents.\+Multiturn\+Teacher.\+get(), parlai.\+tasks.\+wizard\+\_\+of\+\_\+wikipedia.\+agents.\+Wizard\+Of\+Wikipedia\+Teacher.\+get(), parlai.\+tasks.\+flickr30k.\+agents.\+Default\+Teacher.\+get(), parlai.\+tasks.\+empathetic\+\_\+dialogues.\+agents.\+Emotion\+Classification\+Teacher.\+get(), parlai.\+tasks.\+image\+\_\+chat.\+agents.\+Image\+Chat\+Teacher.\+get(), parlai.\+tasks.\+personality\+\_\+captions.\+agents.\+Personality\+Captions\+Teacher.\+get(), parlai.\+tasks.\+wizard\+\_\+of\+\_\+wikipedia.\+agents.\+Wizard\+Dialog\+Knowledge\+Teacher.\+get(), parlai.\+tasks.\+image\+\_\+chat.\+agents.\+Image\+Chat\+Test\+Teacher.\+get(), parlai.\+tasks.\+personality\+\_\+captions.\+agents.\+Personality\+Captions\+Test\+Teacher.\+get(), parlai.\+tasks.\+dialogue\+\_\+safety.\+agents.\+Wiki\+Toxic\+Comments\+Teacher.\+get(), parlai.\+tasks.\+wizard\+\_\+of\+\_\+wikipedia.\+agents.\+Basicdialog\+Teacher.\+get(), parlai.\+core.\+teachers.\+Dialog\+Teacher.\+get(), parlai.\+core.\+teachers.\+Dialog\+Data.\+get(), parlai.\+tasks.\+wizard\+\_\+of\+\_\+wikipedia.\+agents.\+Docreader\+Teacher.\+get(), parlai.\+core.\+teachers.\+Stream\+Dialog\+Data.\+get(), parlai.\+core.\+teachers.\+Abstract\+Image\+Teacher.\+get(), parlai.\+core.\+pytorch\+\_\+data\+\_\+teacher.\+Pytorch\+Data\+Teacher.\+get\+\_\+next\+\_\+batch(), parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+lemmas(), parlai.\+tasks.\+wizard\+\_\+of\+\_\+wikipedia.\+agents.\+Wizard\+Dialog\+Knowledge\+Teacher.\+len\+\_\+episode(), parlai.\+tasks.\+wizard\+\_\+of\+\_\+wikipedia.\+agents.\+Basicdialog\+Teacher.\+len\+\_\+episode(), parlai.\+core.\+teachers.\+Abstract\+Image\+Teacher.\+load\+\_\+data(), parlai.\+core.\+pytorch\+\_\+data\+\_\+teacher.\+Loader\+Process.\+load\+\_\+next(), parlai.\+mturk.\+tasks.\+talkthewalk.\+worlds.\+Talk\+The\+Walk\+World.\+load\+\_\+world(), parlai.\+core.\+teachers.\+Dialog\+Teacher.\+next\+\_\+example(), parlai.\+core.\+pytorch\+\_\+data\+\_\+teacher.\+Pytorch\+Data\+Teacher.\+next\+\_\+example(), parlai.\+tasks.\+ccpe.\+agents.\+C\+C\+P\+E\+All\+Teacher.\+num\+\_\+episodes(), parlai.\+tasks.\+flickr30k.\+agents.\+Flickr\+Dataset.\+num\+\_\+episodes(), parlai.\+tasks.\+talkthewalk.\+base.\+T\+T\+W\+Base.\+num\+\_\+episodes(), parlai.\+tasks.\+image\+\_\+chat.\+agents.\+Default\+Dataset.\+num\+\_\+episodes(), parlai.\+tasks.\+dialogue\+\_\+safety.\+agents.\+Multiturn\+Teacher.\+num\+\_\+episodes(), parlai.\+tasks.\+personality\+\_\+captions.\+agents.\+Default\+Dataset.\+num\+\_\+episodes(), parlai.\+tasks.\+wizard\+\_\+of\+\_\+wikipedia.\+agents.\+Wizard\+Of\+Wikipedia\+Teacher.\+num\+\_\+episodes(), parlai.\+tasks.\+integration\+\_\+tests.\+agents.\+Candidate\+Teacher\+Dataset.\+num\+\_\+episodes(), parlai.\+tasks.\+empathetic\+\_\+dialogues.\+agents.\+Emotion\+Classification\+Teacher.\+num\+\_\+episodes(), parlai.\+tasks.\+image\+\_\+chat.\+agents.\+Image\+Chat\+Teacher.\+num\+\_\+episodes(), parlai.\+tasks.\+dialogue\+\_\+safety.\+agents.\+Wiki\+Toxic\+Comments\+Teacher.\+num\+\_\+episodes(), parlai.\+core.\+teachers.\+Dialog\+Teacher.\+num\+\_\+episodes(), parlai.\+core.\+teachers.\+Dialog\+Data.\+num\+\_\+episodes(), parlai.\+tasks.\+ccpe.\+agents.\+C\+C\+P\+E\+All\+Teacher.\+num\+\_\+examples(), parlai.\+tasks.\+dailydialog.\+agents.\+Convai2\+Teacher.\+num\+\_\+examples(), parlai.\+tasks.\+dialogue\+\_\+nli.\+agents.\+Dialogue\+Nli\+Teacher.\+num\+\_\+examples(), parlai.\+tasks.\+dialogue\+\_\+safety.\+base\+\_\+agent.\+\_\+\+Base\+Safety\+Teacher.\+num\+\_\+examples(), parlai.\+tasks.\+ubuntu.\+agents.\+Multiturn\+Teacher.\+num\+\_\+examples(), parlai.\+tasks.\+dstc7.\+agents.\+D\+S\+T\+C7\+Teacher.\+num\+\_\+examples(), parlai.\+tasks.\+dialogue\+\_\+safety.\+agents.\+Multiturn\+Teacher.\+num\+\_\+examples(), parlai.\+tasks.\+flickr30k.\+agents.\+Default\+Teacher.\+num\+\_\+examples(), parlai.\+tasks.\+empathetic\+\_\+dialogues.\+agents.\+Emotion\+Classification\+Teacher.\+num\+\_\+examples(), parlai.\+tasks.\+image\+\_\+chat.\+agents.\+Image\+Chat\+Teacher.\+num\+\_\+examples(), parlai.\+tasks.\+personality\+\_\+captions.\+agents.\+Personality\+Captions\+Teacher.\+num\+\_\+examples(), parlai.\+tasks.\+dialogue\+\_\+safety.\+agents.\+Wiki\+Toxic\+Comments\+Teacher.\+num\+\_\+examples(), parlai.\+core.\+teachers.\+Dialog\+Teacher.\+num\+\_\+examples(), parlai.\+core.\+teachers.\+Dialog\+Data.\+num\+\_\+examples(), parlai.\+core.\+teachers.\+Abstract\+Image\+Teacher.\+num\+\_\+examples(), parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+offsets(), parlai.\+messenger.\+tasks.\+overworld\+\_\+demo.\+worlds.\+Messenger\+Onboard\+Data\+Onboard\+World.\+parley(), stack\+\_\+rank\+\_\+evals.\+worlds.\+M\+Turk\+Personality\+Captions\+Stack\+Rank\+World.\+parley(), stack\+\_\+rank\+\_\+evals.\+worlds.\+M\+Turk\+Image\+Chat\+Stack\+Rank\+World.\+parley(), igc\+\_\+evals.\+worlds.\+M\+Turk\+I\+G\+C\+Eval\+World.\+parley(), parlai.\+messenger.\+tasks.\+overworld\+\_\+demo.\+worlds.\+Messenger\+Chat\+Onboard\+World.\+parley(), image\+\_\+chat\+\_\+collection.\+worlds.\+M\+Turk\+Image\+Chat\+World.\+parley(), personality\+\_\+captions.\+worlds.\+M\+Turk\+Personality\+Captions\+World.\+parley(), stack\+\_\+rank\+\_\+evals.\+worlds.\+Example\+Generator.\+pop\+\_\+example(), igc\+\_\+evals.\+worlds.\+I\+G\+C\+Example\+Generator.\+pop\+\_\+example(), image\+\_\+chat\+\_\+collection.\+worlds.\+Example\+Generator.\+pop\+\_\+example(), parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+pos(), parlai.\+messenger.\+core.\+agents.\+Messenger\+Agent.\+put\+\_\+data(), parlai.\+core.\+teachers.\+Dialog\+Teacher.\+reset(), parlai.\+core.\+teachers.\+Stream\+Dialog\+Data.\+reset(), parlai.\+core.\+pytorch\+\_\+data\+\_\+teacher.\+Pytorch\+Data\+Teacher.\+reset\+\_\+data(), image\+\_\+chat\+\_\+collection.\+worlds.\+M\+Turk\+Image\+Chat\+World.\+review\+\_\+work(), personality\+\_\+captions.\+worlds.\+M\+Turk\+Personality\+Captions\+World.\+review\+\_\+work(), stack\+\_\+rank\+\_\+evals.\+worlds.\+M\+Turk\+Personality\+Captions\+Stack\+Rank\+World.\+save\+\_\+data(), stack\+\_\+rank\+\_\+evals.\+worlds.\+M\+Turk\+Image\+Chat\+Stack\+Rank\+World.\+save\+\_\+data(), igc\+\_\+evals.\+worlds.\+M\+Turk\+I\+G\+C\+Eval\+World.\+save\+\_\+data(), image\+\_\+chat\+\_\+collection.\+worlds.\+M\+Turk\+Image\+Chat\+World.\+save\+\_\+data(), personality\+\_\+captions.\+worlds.\+M\+Turk\+Personality\+Captions\+World.\+save\+\_\+data(), parlai.\+mturk.\+core.\+dev.\+socket\+\_\+manager.\+Packet.\+set\+\_\+data(), parlai.\+mturk.\+core.\+socket\+\_\+manager.\+Packet.\+set\+\_\+data(), parlai.\+mturk.\+core.\+legacy\+\_\+2018.\+socket\+\_\+manager.\+Packet.\+set\+\_\+data(), parlai.\+core.\+teachers.\+Abstract\+Image\+Teacher.\+setup\+\_\+image\+\_\+features(), parlai.\+tasks.\+talkthewalk.\+base.\+T\+T\+W\+Base.\+share(), mastering\+\_\+the\+\_\+dungeon.\+tasks.\+graph\+\_\+world2.\+agents.\+Default\+Teacher.\+share(), parlai.\+tasks.\+taskntalk.\+agents.\+Task\+N\+Talk\+Teacher.\+share(), parlai.\+tasks.\+dailydialog.\+agents.\+Convai2\+Teacher.\+share(), parlai.\+tasks.\+dialogue\+\_\+safety.\+base\+\_\+agent.\+\_\+\+Base\+Safety\+Teacher.\+share(), parlai.\+tasks.\+ubuntu.\+agents.\+Multiturn\+Teacher.\+share(), parlai.\+tasks.\+dstc7.\+agents.\+D\+S\+T\+C7\+Teacher.\+share(), parlai.\+tasks.\+dialogue\+\_\+safety.\+agents.\+Multiturn\+Teacher.\+share(), parlai.\+tasks.\+empathetic\+\_\+dialogues.\+agents.\+Empathetic\+Dialogue\+Teacher.\+share(), parlai.\+tasks.\+ccpe.\+agents.\+C\+C\+P\+E\+All\+Teacher.\+share(), parlai.\+tasks.\+wizard\+\_\+of\+\_\+wikipedia.\+agents.\+Wizard\+Of\+Wikipedia\+Teacher.\+share(), parlai.\+tasks.\+flickr30k.\+agents.\+Default\+Teacher.\+share(), parlai.\+tasks.\+image\+\_\+chat.\+agents.\+Image\+Chat\+Teacher.\+share(), parlai.\+tasks.\+personality\+\_\+captions.\+agents.\+Personality\+Captions\+Teacher.\+share(), parlai.\+tasks.\+dialogue\+\_\+safety.\+agents.\+Wiki\+Toxic\+Comments\+Teacher.\+share(), parlai.\+core.\+teachers.\+Dialog\+Teacher.\+share(), parlai.\+core.\+teachers.\+Dialog\+Data.\+share(), parlai.\+core.\+pytorch\+\_\+data\+\_\+teacher.\+Pytorch\+Data\+Teacher.\+share(), parlai.\+core.\+teachers.\+Abstract\+Image\+Teacher.\+share(), parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+slice(), parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+untokenize(), and parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+words().

\mbox{\Hypertarget{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_a0edd5b712de93117c645a869bda3206a}\label{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_a0edd5b712de93117c645a869bda3206a}} 
\index{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}!L\+E\+M\+MA@{L\+E\+M\+MA}}
\index{L\+E\+M\+MA@{L\+E\+M\+MA}!parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}}
\subsubsection{\texorpdfstring{L\+E\+M\+MA}{LEMMA}}
{\footnotesize\ttfamily int parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+L\+E\+M\+MA = 4\hspace{0.3cm}{\ttfamily [static]}}



Definition at line 19 of file tokenizer.\+py.



Referenced by parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+lemmas().

\mbox{\Hypertarget{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_a23de330eaa8a95b1eec932b960384516}\label{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_a23de330eaa8a95b1eec932b960384516}} 
\index{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}!N\+ER@{N\+ER}}
\index{N\+ER@{N\+ER}!parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}}
\subsubsection{\texorpdfstring{N\+ER}{NER}}
{\footnotesize\ttfamily int parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+N\+ER = 5\hspace{0.3cm}{\ttfamily [static]}}



Definition at line 20 of file tokenizer.\+py.



Referenced by parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+entities().

\mbox{\Hypertarget{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_ada7339fd7da0200a4260970771f9bfe9}\label{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_ada7339fd7da0200a4260970771f9bfe9}} 
\index{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}!opts@{opts}}
\index{opts@{opts}!parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}}
\subsubsection{\texorpdfstring{opts}{opts}}
{\footnotesize\ttfamily parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+opts}



Definition at line 25 of file tokenizer.\+py.



Referenced by parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+entity\+\_\+groups().

\mbox{\Hypertarget{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_ac86fd8e346abb9582109d8e11e5f9b48}\label{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_ac86fd8e346abb9582109d8e11e5f9b48}} 
\index{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}!P\+OS@{P\+OS}}
\index{P\+OS@{P\+OS}!parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}}
\subsubsection{\texorpdfstring{P\+OS}{POS}}
{\footnotesize\ttfamily int parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+P\+OS = 3\hspace{0.3cm}{\ttfamily [static]}}



Definition at line 18 of file tokenizer.\+py.



Referenced by parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+pos().

\mbox{\Hypertarget{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_a854cddac2a5c84a5d770aa938f304f09}\label{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_a854cddac2a5c84a5d770aa938f304f09}} 
\index{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}!S\+P\+AN@{S\+P\+AN}}
\index{S\+P\+AN@{S\+P\+AN}!parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}}
\subsubsection{\texorpdfstring{S\+P\+AN}{SPAN}}
{\footnotesize\ttfamily int parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+S\+P\+AN = 2\hspace{0.3cm}{\ttfamily [static]}}



Definition at line 17 of file tokenizer.\+py.



Referenced by parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+offsets().

\mbox{\Hypertarget{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_a9aa424cb61b8e4fa45019647aa3a469f}\label{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_a9aa424cb61b8e4fa45019647aa3a469f}} 
\index{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}!T\+E\+XT@{T\+E\+XT}}
\index{T\+E\+XT@{T\+E\+XT}!parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}}
\subsubsection{\texorpdfstring{T\+E\+XT}{TEXT}}
{\footnotesize\ttfamily int parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+T\+E\+XT = 0\hspace{0.3cm}{\ttfamily [static]}}



Definition at line 15 of file tokenizer.\+py.



Referenced by parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+words().

\mbox{\Hypertarget{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_ac1965a5c7e633c9824f5de66b5211325}\label{classparlai_1_1agents_1_1tfidf__retriever_1_1tokenizers_1_1tokenizer_1_1Tokens_ac1965a5c7e633c9824f5de66b5211325}} 
\index{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}!T\+E\+X\+T\+\_\+\+WS@{T\+E\+X\+T\+\_\+\+WS}}
\index{T\+E\+X\+T\+\_\+\+WS@{T\+E\+X\+T\+\_\+\+WS}!parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens@{parlai\+::agents\+::tfidf\+\_\+retriever\+::tokenizers\+::tokenizer\+::\+Tokens}}
\subsubsection{\texorpdfstring{T\+E\+X\+T\+\_\+\+WS}{TEXT\_WS}}
{\footnotesize\ttfamily int parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+T\+E\+X\+T\+\_\+\+WS = 1\hspace{0.3cm}{\ttfamily [static]}}



Definition at line 16 of file tokenizer.\+py.



Referenced by parlai.\+agents.\+tfidf\+\_\+retriever.\+tokenizers.\+tokenizer.\+Tokens.\+untokenize().



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
parlai/agents/tfidf\+\_\+retriever/tokenizers/\hyperlink{tokenizer_8py}{tokenizer.\+py}\end{DoxyCompactItemize}
