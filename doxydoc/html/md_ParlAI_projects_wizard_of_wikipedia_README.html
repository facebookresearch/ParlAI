<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.16"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ParlAI: &lt;img src=&quot;mage.png&quot; alt=&quot;mage&quot;/&gt; Wizard of Wikipedia: Knowledge-Powered Conversational Agents</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">ParlAI
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.16 -->
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',false,false,'search.php','Search');
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title"><img src="mage.png" alt="mage" class="inline"/> Wizard of Wikipedia: Knowledge-Powered Conversational Agents </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p align="center"></p>
<p><img src="parrot.png" alt="" width="15%" class="inline"/></p>
<p>The Wizard of Wikipedia is an open-domain dialogue task for training agents that can converse knowledgably about open-domain topics! A detailed description may be found in <a href="https://arxiv.org/abs/1811.01241">Dinan et al. (ICLR 2019)</a>.</p>
<h1><a class="anchor" id="autotoc_md201"></a>
Abstract</h1>
<p>In open-domain dialogue intelligent agents should exhibit the use of knowledge, however there are few convincing demonstrations of this to date. The most popular sequence to sequence models typically "generate and hope" generic utterances that can be memorized in the weights of the model when mapping from input utterance(s) to output, rather than employing recalled knowledge as context. Use of knowledge has so far proved difficult, in part because of the lack of a supervised learning benchmark task which exhibits knowledgeable open dialogue with clear grounding. To that end we collect and release a large dataset with conversations directly grounded with knowledge retrieved from Wikipedia. We then design architectures capable of retrieving knowledge, reading and conditioning on it, and finally generating natural responses. Our best performing dialogue models are able to conduct knowledgeable discussions on open-domain topics as evaluated by automatic metrics and human evaluations, while our new benchmark allows for measuring further improvements in this important research direction.</p>
<h1><a class="anchor" id="autotoc_md202"></a>
Datasets</h1>
<p>You can train your own ParlAI agent on the Wizard of Wikipedia task with <code>-t wizard_of_wikipedia</code>. See the <a href="http://www.parl.ai/static/docs/tutorial_quick.html">ParlAI quickstart for help</a>.</p>
<p>The ParlAI MTurk collection scripts are also <a href="https://github.com/facebookresearch/ParlAI/tree/master/parlai/mturk/tasks/wizard_of_wikipedia">made available</a>, for those interested in replication, analysis, or additional data collection. The MTurk task for evaluating pre-trained models is made available in this directory.</p>
<h1><a class="anchor" id="autotoc_md203"></a>
Leaderboard</h1>
<h2><a class="anchor" id="autotoc_md204"></a>
Human Evaluations</h2>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Model  </th><th class="markdownTableHeadNone">Paper  </th><th class="markdownTableHeadNone">Seen Rating  </th><th class="markdownTableHeadNone">Unseen Rating   </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Retrieval Trans MemNet  </td><td class="markdownTableBodyNone"><a href="https://arxiv.org/abs/1811.01241">Dinan et al. (2019)</a>  </td><td class="markdownTableBodyNone">3.43  </td><td class="markdownTableBodyNone">3.14   </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Two-stage Generative Trans MemNet  </td><td class="markdownTableBodyNone"><a href="https://arxiv.org/abs/1811.01241">Dinan et al. (2019)</a>  </td><td class="markdownTableBodyNone">2.92  </td><td class="markdownTableBodyNone">2.93   </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Human performance  </td><td class="markdownTableBodyNone"><a href="https://arxiv.org/abs/1811.01241">Dinan et al. (2019)</a>  </td><td class="markdownTableBodyNone">4.13  </td><td class="markdownTableBodyNone">4.34   </td></tr>
</table>
<h2><a class="anchor" id="autotoc_md205"></a>
Retrieval Models</h2>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Model  </th><th class="markdownTableHeadNone">Paper  </th><th class="markdownTableHeadNone">Test Seen R@1  </th><th class="markdownTableHeadNone">Test Unseen R@1   </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Transformer MemNet (w/ pretraining)  </td><td class="markdownTableBodyNone"><a href="https://arxiv.org/abs/1811.01241">Dinan et al. (2019)</a>  </td><td class="markdownTableBodyNone">87.4  </td><td class="markdownTableBodyNone">69.8   </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">BoW Memnet  </td><td class="markdownTableBodyNone"><a href="https://arxiv.org/abs/1811.01241">Dinan et al. (2019)</a>  </td><td class="markdownTableBodyNone">71.3  </td><td class="markdownTableBodyNone">33.1   </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">IR baseline  </td><td class="markdownTableBodyNone"><a href="https://arxiv.org/abs/1811.01241">Dinan et al. (2019)</a>  </td><td class="markdownTableBodyNone">17.8  </td><td class="markdownTableBodyNone">14.2   </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Random  </td><td class="markdownTableBodyNone"><a href="https://arxiv.org/abs/1811.01241">Dinan et al. (2019)</a>  </td><td class="markdownTableBodyNone">1.0  </td><td class="markdownTableBodyNone">1.0   </td></tr>
</table>
<h2><a class="anchor" id="autotoc_md206"></a>
Generative Models</h2>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Model  </th><th class="markdownTableHeadNone">Paper  </th><th class="markdownTableHeadNone">Test Seen PPL  </th><th class="markdownTableHeadNone">Test Unseen PPL   </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">End-to-end Transformer MemNet  </td><td class="markdownTableBodyNone"><a href="https://arxiv.org/abs/1811.01241">Dinan et al. (2019)</a>  </td><td class="markdownTableBodyNone">63.5  </td><td class="markdownTableBodyNone">97.3   </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">Two-Stage Transformer Memnet  </td><td class="markdownTableBodyNone"><a href="https://arxiv.org/abs/1811.01241">Dinan et al. (2019)</a>  </td><td class="markdownTableBodyNone">46.5  </td><td class="markdownTableBodyNone">84.8   </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">Vanilla Transformer (no knowledge)  </td><td class="markdownTableBodyNone"><a href="https://arxiv.org/abs/1811.01241">Dinan et al. (2019)</a>  </td><td class="markdownTableBodyNone">41.8  </td><td class="markdownTableBodyNone">87.0   </td></tr>
</table>
<h1><a class="anchor" id="autotoc_md207"></a>
Viewing data</h1>
<p>You can view the standard training set with: </p><pre class="fragment">python examples/display_data.py -t wizard_of_wikipedia -dt train
</pre><p>The knowledge returned from a standard IR system appears in the knowledge field (but you can also use your own knowledge system, accessing Wikipedia yourself, we use the dump in "-t wikipedia". The field 'checked_sentence' indicates the gold knowledge the annotator labeled.</p>
<h1><a class="anchor" id="autotoc_md208"></a>
Pretrained models</h1>
<h1><a class="anchor" id="autotoc_md209"></a>
End-to-End generative</h1>
<p>You can evaluate the pretrained End-to-end generative models via: </p><pre class="fragment">python examples/eval_model.py \
    -bs 64 -t wizard_of_wikipedia:generator:random_split \
    -mf models:wizard_of_wikipedia/end2end_generator/model
</pre><p>This produces the following metrics: </p><pre class="fragment">{'f1': 0.1717, 'ppl': 61.21, 'know_acc': 0.2201, 'know_chance': 0.02625}
</pre><p>This differs slightly from the results in the paper, as it is a recreation trained from scratch for public release.</p>
<p>You can also evaluate the model on the unseen topic split too: </p><pre class="fragment">python examples/eval_model.py \
    -bs 64 -t wizard_of_wikipedia:generator:topic_split \
    -mf models:wizard_of_wikipedia/end2end_generator/model
</pre><p>This will produce: </p><pre class="fragment">{'f1': 0.1498, 'ppl': 103.1, 'know_acc': 0.1123, 'know_chance': 0.02496}
</pre><p>You can also interact with the model with: </p><pre class="fragment">python examples/interactive.py -m projects:wizard_of_wikipedia:interactive_end2end -t wizard_of_wikipedia
</pre><h1><a class="anchor" id="autotoc_md210"></a>
Retrieval Model</h1>
<p>You can evaluate a retrieval model on the full dialogue task by running the following script: </p><pre class="fragment">python projects/wizard_of_wikipedia/scripts/eval_retrieval_model.py
</pre><p>You can run an interactive session with the model with: </p><pre class="fragment">python examples/interactive.py -m projects:wizard_of_wikipedia:interactive_retrieval -t wizard_of_wikipedia
</pre><p>Check back later for more pretrained models soon!</p>
<h1><a class="anchor" id="autotoc_md211"></a>
Citation</h1>
<p>If you use the dataset or models in your own work, please cite with the following BibTex entry: </p><pre class="fragment">@inproceedings{dinan2019wizard,
  author={Emily Dinan and Stephen Roller and Kurt Shuster and Angela Fan and Michael Auli and Jason Weston},
  title={{W}izard of {W}ikipedia: Knowledge-powered Conversational Agents},
  booktitle = {Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2019},
}
</pre> </div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.16
</small></address>
</body>
</html>
