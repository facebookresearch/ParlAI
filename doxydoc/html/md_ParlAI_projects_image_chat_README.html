<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.16"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ParlAI: Engaging Image Chat: Modeling Personality in Grounded Dialogue</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">ParlAI
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.16 -->
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',false,false,'search.php','Search');
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Engaging Image Chat: Modeling Personality in Grounded Dialogue </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>Kurt Shuster, Samuel Humeau, Antoine Bordes, Jason Weston</p>
<p>Please see <a href="https://arxiv.org/abs/1811.00945">Shuster et al. (2018)</a> for more details.</p>
<h1><a class="anchor" id="autotoc_md127"></a>
Abstract</h1>
<p>To achieve the long-term goal of machines being able to engage humans in conversation, our models should be engaging. We focus on communication grounded in images, whereby a dialogue is conducted based on a given photo, a setup that is naturally engaging to humans (Hu et al., 2014). We collect a large dataset of grounded human-human conversations, where humans are asked to play the role of a given personality, as the use of personality in conversation has also been shown to be engaging (Shuster et al., 2018). Our dataset, ImageChat, consists of 202k dialogues and 401k utterances over 202k images using 215 possible personality traits. We then design a set of natural architectures using state-of-the-art image and text representations, considering various ways to fuse the components. Automatic metrics and human evaluations show the efficacy of approach, in particular where our best performing model is preferred over human conversationalists 47.7% of the time.</p>
<h1><a class="anchor" id="autotoc_md128"></a>
Dataset</h1>
<p>The Image-Chat dataset can be accessed via ParlAI, with <code>-t image_chat</code>.</p>
<p>Additionally, the ParlAI MTurk tasks for data collection and human evaluation are <a href="https://github.com/facebookresearch/ParlAI/tree/master/parlai/mturk/tasks/image_chat">made available</a> in ParlAI.</p>
<h1><a class="anchor" id="autotoc_md129"></a>
Leaderboards for Image-Chat Task</h1>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">Model  </th><th class="markdownTableHeadNone">Paper  </th><th class="markdownTableHeadNone">Test R@1   </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">TransResNet MM-Sum, ResNeXt-IG-3.5B  </td><td class="markdownTableBodyNone"><a href="https://arxiv.org/abs/1811.00945">Shuster et al. (2018)</a>  </td><td class="markdownTableBodyNone">50.3   </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">TransResNet MM-Sum, ResNet152  </td><td class="markdownTableBodyNone"><a href="https://arxiv.org/abs/1811.00945">Shuster et al. (2018)</a>  </td><td class="markdownTableBodyNone">40.6   </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">TransResNet MM-Sum, No Images  </td><td class="markdownTableBodyNone"><a href="https://arxiv.org/abs/1811.00945">Shuster et al. (2018)</a>  </td><td class="markdownTableBodyNone">35.4   </td></tr>
</table>
<h1><a class="anchor" id="autotoc_md130"></a>
Pretrained Models</h1>
<p>We provide our best model trained with ResNet152 image features. To evaluate the model, specify the following command: </p><pre class="fragment">  python examples/eval_model.py \
      -bs 128 -t image_chat
      -mf models:image_chat/transresnet_multimodal/model
      -dt test
</pre><p>Which yields the following results: </p><pre class="fragment">  {'exs': 29991, 'accuracy': 0.4032, 'f1': 0.4432, 'hits@1': 0.403, 'hits@5': 0.672, 'hits@10': 0.779, 'hits@100': 1.0, 'bleu': 0.3923,
  'first_round': {'hits@1/100': 0.3392, 'loss': -0.002001, 'med_rank': 3.0},
  'second_round': {'hits@1/100': 0.4558, 'loss': -0.002001, 'med_rank': 2.0},
  'third_round+': {'hits@1/100': 0.4147, 'loss': -0.002001, 'med_rank': 2.0}}
</pre><p>Additionally, we provide an interactive script that you can use to view outputs of our pretrained model. Simply run the following command: </p><pre class="fragment">  python projects/image_chat/interactive.py \
  -mf models:image_chat/transresnet_multimodal/model
</pre><h1><a class="anchor" id="autotoc_md131"></a>
Model Examples</h1>
<p><img src="Examples.png" alt="" width="85%" class="inline"/></p>
<h1><a class="anchor" id="autotoc_md132"></a>
Citation</h1>
<p>If you use the dataset or models in your own work, please cite with the following BibText entry: </p><pre class="fragment">@article{DBLP:journals/corr/abs-1811-00945,
author    = {Kurt Shuster and
           Samuel Humeau and
           Antoine Bordes and
           Jason Weston},
title     = {Engaging Image Chat: Modeling Personality in Grounded Dialogue},
journal   = {CoRR},
volume    = {abs/1811.00945},
year      = {2018},
url       = {http://arxiv.org/abs/1811.00945},
archivePrefix = {arXiv},
eprint    = {1811.00945},
timestamp = {Thu, 22 Nov 2018 17:58:30 +0100},
biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1811-00945},
bibsource = {dblp computer science bibliography, https://dblp.org}
}
</pre> </div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.16
</small></address>
</body>
</html>
