<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ParlAI: projects/image_chat/README.md Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">ParlAI
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">projects/image_chat/README.md</div>  </div>
</div><!--header-->
<div class="contents">
<a href="projects_2image__chat_2README_8md.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;# Engaging Image Chat: Modeling Personality in Grounded Dialogue</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;Kurt Shuster, Samuel Humeau, Antoine Bordes, Jason Weston</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;</div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;Please see [Shuster et al. (2018)](https://arxiv.org/abs/1811.00945) for more details.</div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;</div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;## Abstract</div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;</div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;To achieve the long-term goal of machines being able to engage humans in conversation, our models should be engaging. We focus on communication grounded in images, whereby a dialogue is conducted based on a given photo, a setup that is naturally engaging to humans (Hu et al., 2014). We collect a large dataset of grounded human-human conversations, where humans are asked to play the role of a given personality, as the use of personality in conversation has also been shown to be engaging (Shuster et al., 2018). Our dataset, ImageChat, consists of 202k dialogues and 401k utterances over 202k images using 215 possible personality traits. We then design a set of natural architectures using state-of-the-art image and text representations, considering various ways to fuse the components. Automatic metrics and human evaluations show the efficacy of approach, in particular where our best performing model is preferred over human conversationalists 47.7% of the time.</div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;</div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;## Dataset</div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;</div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;The Image-Chat dataset can be accessed via ParlAI, with `-t image_chat`.</div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;</div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;Additionally, the ParlAI MTurk tasks for data collection and human evaluation</div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;are [made available](https://github.com/facebookresearch/ParlAI/tree/master/parlai/mturk/tasks/image_chat) in ParlAI.</div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;</div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;## Leaderboards for Image-Chat Task</div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;</div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;</div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;Model                                | Paper          | Test R@1</div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;------------------------------------ | -------------- | --------</div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;TransResNet MM-Sum, ResNeXt-IG-3.5B         | [Shuster et al. (2018)](https://arxiv.org/abs/1811.00945) | 50.3</div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;TransResNet MM-Sum, ResNet152               | [Shuster et al. (2018)](https://arxiv.org/abs/1811.00945) | 40.6</div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;TransResNet MM-Sum, No Images               | [Shuster et al. (2018)](https://arxiv.org/abs/1811.00945) | 35.4</div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;</div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;</div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;## Pretrained Models</div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;</div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;We provide our best model trained with ResNet152 image features. To evaluate the model, specify the following command:</div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;</div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;      python examples/eval_model.py \</div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;          -bs 128 -t image_chat</div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;          -mf models:image_chat/transresnet_multimodal/model</div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;          -dt test</div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;</div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;Which yields the following results:</div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;</div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;      {&#39;exs&#39;: 29991, &#39;accuracy&#39;: 0.4032, &#39;f1&#39;: 0.4432, &#39;hits@1&#39;: 0.403, &#39;hits@5&#39;: 0.672, &#39;hits@10&#39;: 0.779, &#39;hits@100&#39;: 1.0, &#39;bleu&#39;: 0.3923,</div><div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;      &#39;first_round&#39;: {&#39;hits@1/100&#39;: 0.3392, &#39;loss&#39;: -0.002001, &#39;med_rank&#39;: 3.0},</div><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;      &#39;second_round&#39;: {&#39;hits@1/100&#39;: 0.4558, &#39;loss&#39;: -0.002001, &#39;med_rank&#39;: 2.0},</div><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;      &#39;third_round+&#39;: {&#39;hits@1/100&#39;: 0.4147, &#39;loss&#39;: -0.002001, &#39;med_rank&#39;: 2.0}}</div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;</div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;Additionally, we provide an interactive script that you can use to view outputs of our pretrained model. Simply run the following command:</div><div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;</div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;      python projects/image_chat/interactive.py \</div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;      -mf models:image_chat/transresnet_multimodal/model</div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;</div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;## Model Examples</div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;</div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;&lt;p align=&quot;center&quot;&gt;&lt;img width=&quot;85%&quot; src=&quot;Examples.png&quot; /&gt;&lt;/p&gt;</div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;</div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;## Citation</div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;</div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;If you use the dataset or models in your own work, please cite with the following BibText entry:</div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;</div><div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;    @article{DBLP:journals/corr/abs-1811-00945,</div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;    author    = {Kurt Shuster and</div><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;               Samuel Humeau and</div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;               Antoine Bordes and</div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;               Jason Weston},</div><div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;    title     = {Engaging Image Chat: Modeling Personality in Grounded Dialogue},</div><div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;    journal   = {CoRR},</div><div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;    volume    = {abs/1811.00945},</div><div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;    year      = {2018},</div><div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;    url       = {http://arxiv.org/abs/1811.00945},</div><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;    archivePrefix = {arXiv},</div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;    eprint    = {1811.00945},</div><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;    timestamp = {Thu, 22 Nov 2018 17:58:30 +0100},</div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;    biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1811-00945},</div><div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;    bibsource = {dblp computer science bibliography, https://dblp.org}</div><div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;    }</div></div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
